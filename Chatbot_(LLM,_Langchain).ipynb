{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMklwftwvWJ5exLuCK+VwmX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShravanBalaji2004/2022305502Shravan/blob/main/Chatbot_(LLM%2C_Langchain).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "r_XI0vaB8QG0",
        "outputId": "4677021c-5a14-41dd-ab3b-95e083a4a5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f5dee22396ae>:41: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¤– Gemini Chatbot is ready! Type 'exit' to quit.\n",
            "You: hi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f5dee22396ae>:51: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = chain.run({\"question\": query})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini: Hello\n"
          ]
        }
      ],
      "source": [
        "# âœ… STEP 1: Install required packages\n",
        "!pip install -q google-generativeai langchain\n",
        "\n",
        "# âœ… STEP 2: Imports\n",
        "import google.generativeai as genai\n",
        "from langchain.llms.base import LLM\n",
        "from langchain.schema import LLMResult\n",
        "from typing import Optional, List\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# âœ… STEP 3: Configure your Gemini API key\n",
        "GEMINI_API_KEY = \"AIzaSyBcHP-3BFrnyzh0wPdMMkoNsGtrtYpbIC4\"  # ðŸ‘ˆ Replace this with your API key from AI Studio\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# âœ… STEP 4: Create a custom LLM wrapper for Gemini\n",
        "class GeminiLLM(LLM):\n",
        "    model_name: str = \"gemini-1.5-pro\"\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        model = genai.GenerativeModel(self.model_name)\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"gemini-llm\"\n",
        "\n",
        "# âœ… STEP 5: Setup LangChain Prompt & Chain\n",
        "template = \"\"\"You are a helpful assistant. Answer the following question clearly and concisely.\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "llm = GeminiLLM()\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# âœ… STEP 6: Create a simple chatbot loop\n",
        "def chatbot():\n",
        "    print(\"ðŸ¤– Gemini Chatbot is ready! Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        query = input(\"You: \")\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"ðŸ‘‹ Goodbye!\")\n",
        "            break\n",
        "        response = chain.run({\"question\": query})\n",
        "        print(\"Gemini:\", response)\n",
        "\n",
        "# âœ… STEP 7: Run chatbot\n",
        "chatbot()"
      ]
    }
  ]
}